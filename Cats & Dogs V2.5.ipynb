{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cats vs Dogs"},{"metadata":{},"cell_type":"markdown","source":"## Initialisations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline\n\n# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import datasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import mnist\n\nfrom keras.models import Sequential, load_model\n\nfrom keras.layers import Dense, Dropout, Flatten\n\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nfrom keras.utils.np_utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Permet d'éviter les erreurs mémoires pour le GPU\nimport tensorflow as tf\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.Session(config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scores(train) :\n    accuracy = train.history['acc']\n    val_accuracy = train.history['val_acc']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Affichage des fichiers dans le répertoire de données Kaggle\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importation des images"},{"metadata":{},"cell_type":"markdown","source":"On utilise *ImageDataGenerator*, à la fois pour charger les images à partir d'un répertoire, et pour augmenter le nombre d'images.\n\nOn augmente le nombre d'images en appliquant des transformations simples (rotation, retournement, décalage, ...)\n- **rotation_range** est une valeur en degrés (0-180), une plage à l'intérieur de laquelle les images peuvent tourner aléatoirement\n- **width_shift** et **height_shift** sont des plages (en tant que fraction de la largeur ou de la hauteur totale) dans lesquelles les images peuvent être traduites aléatoirement verticalement ou horizontalement.\n- **rescale** est une valeur par laquelle nous allons multiplier les données avant tout autre traitement. Nos images originales consistent en des coefficients RVB dans le 0-255, mais ces valeurs seraient trop élevées pour que nos modèles puissent les traiter (compte tenu d'un taux d'apprentissage typique), alors nous ciblons des valeurs entre 0 et 1 en utilisant plutôt un facteur 1/255.\n- **shear_range** est pour l'application aléatoire de transformations de cisaillement\n- **zoom_range** est pour zoomer aléatoirement à l'intérieur des images\n- **horizontal_flip** est pour retourner aléatoirement la moitié des images horizontalement --pertinent quand il n'y a pas de suppositions d'asymétrie horizontale (par exemple, des images du monde réel).\n- **fill_mode** est la stratégie utilisée pour remplir les pixels nouvellement créés, qui peuvent apparaître après une rotation ou un décalage largeur/hauteur.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\nvalid_datagen = ImageDataGenerator(\n        rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*flow_from_directory* permet de lire les images directement à partir d'un répertoire.  \nIci les images d'apprentissage sont dans un répertoire **CatsDogs2\\train*"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory=\"../input/cat-and-dog/training_set/training_set/\",\n    target_size=(64, 64),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator = valid_datagen.flow_from_directory(\n    directory=\"../input/cat-and-dog/test_set/test_set/\",\n    target_size=(64, 64),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_generator.n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(*valid_generator[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(valid_generator[0][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modèle CNN"},{"metadata":{},"cell_type":"markdown","source":"On teste un modèle avec deux couches convolutionnelles :"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modèle CNN plus profond\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(64, 64, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le nombres d'images générées à chaque epoch est *steps_by_epoch x batch_size*. Ici on génère 10 fois plus d'images à partir du dataset d'apprentissage (ce qui ralentit évidemment l'apprentissage)"},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=3*train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=valid_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\ny_pred = model.predict_generator(valid_generator,verbose=1).argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nlabels = ['cat','dog']\nplt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\nfor i in range(1,50) :\n    ir = random.randint(0,n_test)\n    plt.subplot(10,5,i)\n    plt.axis('off')\n    plt.imshow(*valid_generator[ir][0])\n    plt.title(labels[y_pred[ir]])\n#    plt.title('%s / %s' % (y_cnn_classe[ir], y_test_classe[ir]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importation des images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory=\"CatsDogs2\\\\train\",\n    target_size=(64, 64),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator = valid_datagen.flow_from_directory(\n    directory=\"CatsDogs2\\\\valid\",\n    target_size=(64, 64),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=valid_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory=\"CatsDogs2\\\\train\",\n    target_size=(64, 64),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator = valid_datagen.flow_from_directory(\n    directory=\"CatsDogs2\\\\valid\",\n    target_size=(64, 64),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modèle VGG16\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), input_shape=(64, 64, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=valid_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nmodel = Sequential()\nmodel.add(VGG16(weights=None, input_tensor=None, input_shape=(64,64,3), classes=2))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import ResNet\nmodel = Sequential()\nmodel.add(ResNet(weights=None, input_tensor=None, input_shape=(64,64,3), classes=2))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}