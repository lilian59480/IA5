{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Impayés carte bancaire"},{"metadata":{},"cell_type":"markdown","source":"On cherche à prédire des fraudes ou impayés à la carte bancaire\n"},{"metadata":{},"cell_type":"markdown","source":"## Librairies et fonctions utiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour standardiser les données quantitatives (cont_feat est une liste des colonnes correspondant à des caractéristiques quantitatives) :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_feat(df,cont_feat) :\n    df1=df\n    scaler = preprocessing.RobustScaler()\n    df1[cont_feat] = scaler.fit_transform(df1[cont_feat])\n    scaler = preprocessing.StandardScaler()\n    df1[cont_feat] = scaler.fit_transform(df1[cont_feat]) \n    return df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour tracer les courbes d'apprentissage sur l'ensemble d'apprentissage et l'ensemble de validation :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour tracer la courbe ROC :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour équilibrer un dataframe *df* sur la colonne cible *target_col* avec la classe minoritaire *minority_class* :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def undersample(df, target_col, minority_class) :\n    df_minority = df[df[target_col] == minority_class]\n    df_majority = df.drop(df_minority.index)\n    ratio=len(df_minority)/len(df_majority)\n    df_majority = df_majority.sample(frac=ratio)\n    df1 = pd.concat((df_majority,df_minority), axis=0)\n    return df1.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Traitement du dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/creditcard_uci.csv\", sep=';')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ce dataset contient des informations sur les défauts de paiement, les facteurs démographiques, les données de crédit, l'historique des paiements et les relevés de factures des clients de cartes de crédit à Taiwan d'avril 2005 à septembre 2005.\n\n- ID: ID of each client\n- LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n- SEX: Gender (1=male, 2=female)\n- EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n- MARRIAGE: Marital status (1=married, 2=single, 3=others)\n- AGE: Age in years\n- PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n- PAY_2: Repayment status in August, 2005 (scale same as above)\n- PAY_3: Repayment status in July, 2005 (scale same as above)\n- PAY_4: Repayment status in June, 2005 (scale same as above)\n- PAY_5: Repayment status in May, 2005 (scale same as above)\n- PAY_6: Repayment status in April, 2005 (scale same as above)\n- BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n- BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n- BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n- BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n- BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n- BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n- PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n- PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n- PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n- PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n- PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n- PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n- **CLASS: Default payment next month (1=yes, 0=no)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exercice : prédire le défaut de paiement"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('ID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(df, hue=\"CLASS\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df[\"PAY_AMT1\"], bins=20)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.hist(df[\"PAY_AMT2\"], bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['CLASS'], axis=1)\ny = df['CLASS']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runClassifier(est, X_train, y_train, X_test, y_test):\n    est.fit(X_train,y_train)\n    y_est = est.predict(X_test)\n    \n    est_score = metrics.accuracy_score(y_test, y_est)\n    print(\"Accuracy score :\", est_score)\n\n    class_score = metrics.classification_report(y_test, y_est)\n    print(\"Classification report :\", class_score)\n\n    cm = metrics.confusion_matrix(y_test, y_est)\n    print(\"Confusion matrix :\", cm)\n    \n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    print(\"Roc :\", roc_auc)\n    \n    plot_roc_curve(est,X_test,y_test)\n    plot_learning_curve(est, X_train, y_train)\n    \n    return (est, y_est, est_score, class_score, cm, probas, roc_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\n\nrunClassifier(lr, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\n\nrunClassifier(rf, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(figsize=(8,5))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns[indices])\nplt.title('Importance des caracteristiques')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Under sampling -> Logistric Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import TomekLinks\n\ntl = TomekLinks(return_indices=True, ratio='majority')\nX_tl, y_tl, i_tl = tl.fit_sample(X_train, y_train)\n\nlrus = LogisticRegression()\nlrus.fit(X_tl, y_tl)\ny_lrus = lrus.predict(X_test)\n\nprint(metrics.classification_report(y_test, y_lrus))\ncm = metrics.confusion_matrix(y_test, y_lrus)\nprint(cm)\n\nprobas = lrus.predict_proba(X_test)\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(lrus, X_train, y_train)\nplot_roc_curve(lrus,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Over sampling -> Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(ratio='minority')\nX_smote, y_smote = smote.fit_sample(X_train, y_train)\n\nlros = LogisticRegression()\nlros.fit(X_smote, y_smote)\ny_lros = lros.predict(X_test)\n\nprint(metrics.classification_report(y_test, y_lros))\ncm = metrics.confusion_matrix(y_test, y_lros)\nprint(cm)\n\nprobas = lros.predict_proba(X_test)\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(lros, X_train, y_train)\nplot_roc_curve(lros,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Under and Over Sampling -> Logistric Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek\n\nsmt = SMOTETomek(ratio='auto')\nX_smt, y_smt = smt.fit_sample(X_train, y_train)\n\nlrboth = LogisticRegression()\nlrboth.fit(X_smt, y_smt)\ny_lrboth = lrboth.predict(X_test)\n\nprint(metrics.classification_report(y_test, y_lrboth))\ncm = metrics.confusion_matrix(y_test, y_lrboth)\nprint(cm)\n\nprobas = lrboth.predict_proba(X_test)\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(lrboth, X_train, y_train)\nplot_roc_curve(lrboth,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\nprint(xgb.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_xgb = xgb.predict(X_test)\ncm = metrics.confusion_matrix(y_test, y_xgb)\nprint(cm)\nxgb_score = metrics.accuracy_score(y_test, y_xgb)\nprint(xgb_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(xgb, X_train, y_train)\nplot_roc_curve(xgb,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_xgb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Search"},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n              'n_estimators': [10, 100, 500],\n              'min_samples_leaf': [1, 20, 50]\n             }\nestimator = ensemble.RandomForestClassifier()\nrf_gs = model_selection.GridSearchCV(estimator, param_grid)\n\nrf_gs.fit(X_train, y_train)\n\nprint(rf_gs.best_params_)\n\nrfbest = rf_gs.best_estimator_\n\nrunClassifier(rfbest, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":1}